{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 붓꽃 품종 예측하기\n",
    "- 데이터: 내장 예제 데이터 셋 - 연습용 예제 데이터 - iris\n",
    "- 알고리즘: 분류- 의사결정트리(Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 준비\n",
    "- 데이터 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris target값:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "iris target명:  ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "#iris.data는 데이터셋에서 피처만으로 된 데이터를 numpy로 가지고 있음\n",
    "iris_data = iris.data\n",
    "\n",
    "# print('iris feature값: ', iris_data)\n",
    "iris_label = iris.target\n",
    "print('iris target값: ', iris_label)\n",
    "print('iris target명: ', iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 붓꽃 품종 데이터 확인\n",
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data, Test Data 분리\n",
    "- 학습용 피처 데이터: x_train, 테스트용 피처 데이터: x_test\n",
    "- 학습용 레이블 데이터: y_train, 테스트용 피처 데이터: y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(iris_data, iris_label, test_size=0.2, random_state=11)\n",
    "# 20%가 테스트 데이터, 80%가 학습 데이터\n",
    "# random_state를 지정하지 않으면 호출할 때 마다 다른 데이터 만들 수 있음\n",
    "# 동일한 데이터셋으로 분리하기 위해 일정한 숫자값으로 부여"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 알고리즘 선택/모델 학습/예측/평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=11)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=11)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=11)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clf = DecisionTreeClassifier(random_state=11)\n",
    "df_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 1, 2, 0, 1, 0, 0, 1, 1, 1, 1, 2, 2, 0, 2, 1, 2, 2, 1, 0,\n",
       "       0, 1, 0, 0, 2, 1, 0, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측값 반환\n",
    "pred = df_clf.predict(x_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 0.9333\n"
     ]
    }
   ],
   "source": [
    "# accuracy_score(실제 레이블 데이터 셋, 예측 레이블 데이터 셋)\n",
    "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clf = DecisionTreeClassifier()\n",
    "iris_data = load_iris()\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.3, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 1, 2, 2, 2, 0, 2, 0, 1, 0, 0, 0, 1, 2, 2, 1, 0, 2, 0, 1,\n",
       "       2, 1, 0, 2, 2, 1, 0, 0, 0, 1, 2, 0, 2, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clf.fit(x_train, y_train)\n",
    "pred = df_clf.predict(x_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 0.9556\n"
     ]
    }
   ],
   "source": [
    "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 카테고리별로 50개씩 밖에 없어서 머신러닝 학습하기엔 데이터의 양이 적다.   \n",
    "데이터를 증폭시켜서 크로스로 테스팅 하는 방법이 있다 - **교차검증**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 교차검증\n",
    "- overfitting을 방지하기 위해 소량의 데이터를 학습시키기 위한 최적의 모델   \n",
    "- 데이터셋은 K등분하고 처음부터 4등분을 학습 데이터셋, 마지막을 검증 데이터셋으로 설정하고 학습을 수행, 검증 데이터셋에서 평가를 수행\n",
    "- StratifiedKFold: 불균형한 분포도를 가진 레이블 데이터 집합일 경우\n",
    "- 회귀일 때는 KFold, 불균형한 데이터는 StratifiedKFold   \n",
    "<img src=\"http://androidkt.com/wp-content/uploads/2021/07/Selection_103.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 세트 크기:  150\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "# 5개의 폴드세트로 분리하는 kfold 객체\n",
    "kfold = KFold(n_splits=5)\n",
    "# 세트별 정확도를 담을 리스트\n",
    "cv_accuracy = []\n",
    "print('붓꽃 데이터 세트 크기: ', features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차 검증 정확도: 1.0, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#1 검증 세트 인덱스: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "#2 교차 검증 정확도: 0.9667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#2 검증 세트 인덱스: [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "\n",
      "#3 교차 검증 정확도: 0.8667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#3 검증 세트 인덱스: [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "\n",
      "#4 교차 검증 정확도: 0.9333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#4 검증 세트 인덱스: [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "\n",
      "#5 교차 검증 정확도: 0.7333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#5 검증 세트 인덱스: [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "## 평균 검증 정확도:  0.9\n"
     ]
    }
   ],
   "source": [
    "n_iter = 0\n",
    "for train_index, test_index in kfold.split(features):\n",
    "    x_train, x_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "\n",
    "    dt_clf.fit(x_train, y_train)\n",
    "    pred = dt_clf.predict(x_test)\n",
    "    n_iter += 1\n",
    "\n",
    "    accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "    train_size = x_train.shape[0]\n",
    "    test_size = x_test.shape[0]\n",
    "\n",
    "    print('\\n#{0} 교차 검증 정확도: {1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'.format(n_iter, accuracy, train_size, test_size))\n",
    "    print('#{0} 검증 세트 인덱스: {1}'.format(n_iter, test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "\n",
    "print('\\n## 평균 검증 정확도: ', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50\n",
       "1    50\n",
       "2    50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "iris_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차 검증: 1\n",
      "학습 레이블 데이터 분포:\n",
      " 1    50\n",
      "2    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 0    50\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증: 2\n",
      "학습 레이블 데이터 분포:\n",
      " 0    50\n",
      "2    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 1    50\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증: 3\n",
      "학습 레이블 데이터 분포:\n",
      " 0    50\n",
      "1    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 2    50\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=3)\n",
    "n_iter = 0\n",
    "for train_index, test_index in kfold.split(iris_df):\n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print('## 교차 검증: {0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차 검증: 1\n",
      "학습 레이블 데이터 분포:\n",
      " 2    34\n",
      "0    33\n",
      "1    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 0    17\n",
      "1    17\n",
      "2    16\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증: 2\n",
      "학습 레이블 데이터 분포:\n",
      " 1    34\n",
      "0    33\n",
      "2    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 0    17\n",
      "2    17\n",
      "1    16\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증: 3\n",
      "학습 레이블 데이터 분포:\n",
      " 0    34\n",
      "1    33\n",
      "2    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 1    17\n",
      "2    17\n",
      "0    16\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print('## 교차 검증: {0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차 검증 정확도: 0.98, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
      "#1 검증 세트 인덱스: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n",
      "\n",
      "#2 교차 검증 정확도: 0.94, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
      "#2 검증 세트 인덱스: [ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
      "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n",
      "\n",
      "#3 교차 검증 정확도: 0.98, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
      "#3 검증 세트 인덱스: [ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
      "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "## 교차 검증별 정확도:  [0.98 0.94 0.98]\n",
      "\n",
      "## 평균 검증 정확도:  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "skfold = StratifiedKFold(n_splits=3)\n",
    "n_iter = 0\n",
    "cv_accuracy = []\n",
    "\n",
    "for train_index, test_index in skfold.split(features, label):\n",
    "    x_train, x_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "\n",
    "    dt_clf.fit(x_train, y_train)\n",
    "    pred = dt_clf.predict(x_test)\n",
    "\n",
    "    n_iter += 1\n",
    "    accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "    train_size = x_train.shape[0]\n",
    "    test_size = x_test.shape[0]\n",
    "\n",
    "    print('\\n#{0} 교차 검증 정확도: {1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'.format(n_iter, accuracy, train_size, test_size))\n",
    "    print('#{0} 검증 세트 인덱스: {1}'.format(n_iter, test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "\n",
    "print('\\n## 교차 검증별 정확도: ', np.round(cv_accuracy, 4))\n",
    "print('\\n## 평균 검증 정확도: ', np.mean(cv_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `cross_val_score()`: 간편한 교차검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도:  [0.98 0.94 0.98]\n",
      "평균 검증 정확도:  0.9667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "iris_data = load_iris()\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "data = iris_data.data\n",
    "label = iris_data.target\n",
    "\n",
    "# 분류면 StratifiedKFold, 회귀는 KFold로 알아서 설정\n",
    "scores = cross_val_score(dt_clf, data, label, scoring='accuracy', cv=3)\n",
    "print('교차 검증별 정확도: ', np.round(scores, 4))\n",
    "print('평균 검증 정확도: ', np.round(np.mean(scores), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `GridSearchCV`: 교차 검증+하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "iris_data = load_iris()\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.2, random_state=121)\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "# 파라미터를 딕셔너리 형태로 설정\n",
    "parameters = {\n",
    "    'max_depth': [1, 2, 3], # 트리의 최대 깊이(default=None): 클래스값이 결정될 때 까지 분할\n",
    "    'min_samples_split': [2, 3] # 노드를 분할하기 위한 최소한의 샘플 데이터 수 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.700000                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.700000                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.975000                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.975000                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0              0.700                0.7               0.70  \n",
       "1              0.700                0.7               0.70  \n",
       "2              0.925                1.0               0.95  \n",
       "3              0.925                1.0               0.95  \n",
       "4              0.975                1.0               0.95  \n",
       "5              0.975                1.0               0.95  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=3, refit=True)\n",
    "grid_dtree.fit(x_train, y_train)\n",
    "\n",
    "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df[['params', 'mean_test_score', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라미터:  {'max_depth': 3, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 정확도: 0.9750\n"
     ]
    }
   ],
   "source": [
    "print('GridSearchCV 최적 파라미터: ', grid_dtree.best_params_)\n",
    "print('GridSearchCV 최고 정확도: {0:.4f}'.format(grid_dtree.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 세트 정확도: 0.9667\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV의 refit으로 이미 학습된 estimator 반환\n",
    "estimator = grid_dtree.best_estimator_\n",
    "\n",
    "# 이미 최적 학습이 됐으므로 별도 학습이 필요 없음\n",
    "pred = estimator.predict(x_test)\n",
    "print('테스트 데이터 세트 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('study')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2cfda4edd5fd29a80a355332d4a199ceff4e11192a2c7367aec533c8ff01e680"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
